{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto-encoder (PyTorch)\n",
    "Create a generative model for MNIST images.\n",
    "<br>Reference Link: [Variational Autoencoders Explained](http://kvfrans.com/variational-autoencoders-explained/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal(object):\n",
    "    def __init__(self, mu, sigma, log_sigma, v=None, r=None):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma  # either stdev diagonal itself, or stdev diagonal from decomposition\n",
    "        self.logsigma = log_sigma\n",
    "        dim = mu.get_shape()\n",
    "        if v is None:\n",
    "            v = torch.FloatTensor(*dim)\n",
    "        if r is None:\n",
    "            r = torch.FloatTensor(*dim)\n",
    "        self.v = v\n",
    "        self.r = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deconvolution](http://kvfrans.com/content/images/2016/08/dat.jpg)\n",
    "![Autoencode](http://kvfrans.com/content/images/2016/08/autoenc.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    latent_dim = 8\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self._enc_mu = torch.nn.Linear(100, 8)\n",
    "        self._enc_log_sigma = torch.nn.Linear(100, 8)\n",
    "\n",
    "    def _sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        mu = self._enc_mu(h_enc)\n",
    "        log_sigma = self._enc_log_sigma(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_sigma = sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
    "\n",
    "    def forward(self, state):\n",
    "        h_enc = self.encoder(state)\n",
    "        z = self._sample_latent(h_enc)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder(VAE)는 두가지 요소에 대한 정확도를 학습합니다.\n",
    "- 이미지를 얼마나 정확하게 Generate했는가\n",
    "- Latent variable이 unit gaussian에 얼마나 근접했는가\n",
    "    - 이를 측정하기 위해 KL-divergence를 사용합니다\n",
    "    - 여기서는 실제 값의 모든 vector를 사용하는 대신 평균(mean)과 분포(standard deviation) vector만을 사용합니다.\n",
    "\n",
    "위 두 요소 사이에는 trade-off가 있습니다.\n",
    "\n",
    "```code\n",
    "generation_loss = mean(square(generated_image - real_image))  \n",
    "latent_loss = KL-Divergence(latent_variable, unit_gaussian)  \n",
    "loss = generation_loss + latent_loss\n",
    "```\n",
    "\n",
    "그림으로 나타내면 아래와 같습니다.\n",
    "![VAE](http://kvfrans.com/content/images/2016/08/vae.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(z_mean, z_stddev):\n",
    "    mean_sq = z_mean * z_mean\n",
    "    stddev_sq = z_stddev * z_stddev\n",
    "    return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  60000\n"
     ]
    }
   ],
   "source": [
    "input_dim = 28 * 28\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "mnist = torchvision.datasets.MNIST('./', download=True, transform=transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(mnist, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "print('Number of samples: ', len(mnist))\n",
    "\n",
    "encoder = Encoder(input_dim, 100, 100)\n",
    "decoder = Decoder(8, 100, input_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.0001)\n",
    "l = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0663687139749527\n",
      "1 0.0690300241112709\n",
      "2 0.06314890831708908\n",
      "3 0.0687660351395607\n",
      "4 0.0712401419878006\n",
      "5 0.06650761514902115\n",
      "6 0.06941360235214233\n",
      "7 0.06615210324525833\n",
      "8 0.0631953626871109\n",
      "9 0.06980690360069275\n",
      "10 0.06972867250442505\n",
      "11 0.0643949955701828\n",
      "12 0.062161222100257874\n",
      "13 0.06403818726539612\n",
      "14 0.06886661797761917\n",
      "15 0.06459414958953857\n",
      "16 0.0682990700006485\n",
      "17 0.0761084035038948\n",
      "18 0.06664256006479263\n",
      "19 0.06773415952920914\n",
      "20 0.06767349690198898\n",
      "21 0.06547828018665314\n",
      "22 0.06525144726037979\n",
      "23 0.06317349523305893\n",
      "24 0.06219231337308884\n",
      "25 0.06615196168422699\n",
      "26 0.07227176427841187\n",
      "27 0.062339406460523605\n",
      "28 0.07176733016967773\n",
      "29 0.06655406206846237\n",
      "30 0.06663045287132263\n",
      "31 0.06796737015247345\n",
      "32 0.06757582724094391\n",
      "33 0.0661088228225708\n",
      "34 0.06294684112071991\n",
      "35 0.0647888258099556\n",
      "36 0.06897665560245514\n",
      "37 0.06624607741832733\n",
      "38 0.07474660128355026\n",
      "39 0.06834234297275543\n",
      "40 0.06798367947340012\n",
      "41 0.0684843510389328\n",
      "42 0.06374235451221466\n",
      "43 0.06740977615118027\n",
      "44 0.06908732652664185\n",
      "45 0.06817267835140228\n",
      "46 0.06759408861398697\n",
      "47 0.06487336754798889\n",
      "48 0.06865627318620682\n",
      "49 0.06600907444953918\n",
      "50 0.0643758699297905\n",
      "51 0.06593643873929977\n",
      "52 0.07100658118724823\n",
      "53 0.06551233679056168\n",
      "54 0.07120410352945328\n",
      "55 0.06625615060329437\n",
      "56 0.06784781068563461\n",
      "57 0.07280618697404861\n",
      "58 0.06971339136362076\n",
      "59 0.06968003511428833\n",
      "60 0.06788551062345505\n",
      "61 0.06271463632583618\n",
      "62 0.0637848973274231\n",
      "63 0.0701085776090622\n",
      "64 0.06113574281334877\n",
      "65 0.06857242435216904\n",
      "66 0.0661662220954895\n",
      "67 0.06648129969835281\n",
      "68 0.06636551767587662\n",
      "69 0.07208956778049469\n",
      "70 0.06233492121100426\n",
      "71 0.06484011560678482\n",
      "72 0.07067351043224335\n",
      "73 0.06847511976957321\n",
      "74 0.07313652336597443\n",
      "75 0.07334029674530029\n",
      "76 0.06744498014450073\n",
      "77 0.06952521950006485\n",
      "78 0.06705449521541595\n",
      "79 0.06767024844884872\n",
      "80 0.0712704136967659\n",
      "81 0.06616368889808655\n",
      "82 0.06560409814119339\n",
      "83 0.0722389668226242\n",
      "84 0.06921027600765228\n",
      "85 0.07574520260095596\n",
      "86 0.06609088182449341\n",
      "87 0.07206396013498306\n",
      "88 0.06750921905040741\n",
      "89 0.07132874429225922\n",
      "90 0.06359227001667023\n",
      "91 0.06754565238952637\n",
      "92 0.06757312268018723\n",
      "93 0.062128946185112\n",
      "94 0.06499120593070984\n",
      "95 0.07287224382162094\n",
      "96 0.06568360328674316\n",
      "97 0.07179038971662521\n",
      "98 0.06923212856054306\n",
      "99 0.07000159472227097\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, classes = data\n",
    "        inputs, classes = Variable(inputs.resize_(batch_size, input_dim)), Variable(classes)\n",
    "        optimizer.zero_grad()\n",
    "        dec = vae(inputs)\n",
    "        ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "        loss = criterion(dec, inputs) + ll\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()    # loss.data[0] will produce warning in PyTorch 0.4\n",
    "    print(epoch, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD/1JREFUeJzt3V9o3fd5x/HPE0f+J/+TY0tWbMd2ShgdgaVDmEHGyCgp2SgkvWioL4YHpe5FAyv0oiE3zc0gjLVdrwoqMXWgTVtos/iibA1hkA1GiBNCk9Z1HRzFlq3Ilv/Esh3Hsv3sQr8M1dH5Pifnd/7Jz/sFQUfnOT+dr47y8e9Iz+/7/Zq7C0A+d/R6AAB6g/ADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0jqzm4+mZlxOSHQYe5uzTyu1pnfzB4xsyNm9o6ZPVnnawHoLmv12n4zWybpj5IeljQp6TVJe9z994VjOPMDHdaNM/9uSe+4+zF3vybpZ5IerfH1AHRRnfBvlXRiweeT1X1/wsz2mdkhMztU47kAtFmdP/gt9tbiE2/r3X1c0rjE236gn9Q5809K2r7g822STtUbDoBuqRP+1yTdZ2a7zGy5pK9IOtieYQHotJbf9rv7dTN7QtJ/Slomab+7/65tIwPQUS23+lp6Mn7nBzquKxf5AFi6CD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKqrS3dj6dmwYUOxPjAwUKybNZ5gFs0onZubK9YvXLhQrKOMMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEWfvw+sX7++WI966WvWrGlYi/r0pWOleGzLly8v1ku9/I8++qh47OzsbK36+fPnO3Ls7YIzP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kVavPb2YTkmYl3ZB03d3H2jGo283w8HCxHvXih4aGivW77767YW379u0tHyvFYx8cHCzWb9y40bB28eLF4rFTU1PF+rvvvlusv/feew1rJ0+eLB4bXb8QXSdw5cqVYr0ftOMin79195k2fB0AXcTbfiCpuuF3Sb8xs9fNbF87BgSgO+q+7X/Q3U+Z2bCkl8zsD+7+ysIHVP8o8A8D0Gdqnfnd/VT18bSkFyTtXuQx4+4+xh8Dgf7ScvjNbNDM1n58W9IXJL3droEB6Kw6b/tHJL1QLc18p6Sfuvt/tGVUADqu5fC7+zFJf9HGsSxZUS88qo+MjBTr99xzT7F+7733Nqzt3Lmz1tfesmVLsb569epi/ebNmw1rH3zwQfHYUp9ektatW1esL1u2rGEt2jPg1KlTxXq0FsG1a9eK9evXrxfr3UCrD0iK8ANJEX4gKcIPJEX4gaQIP5AUS3c36a677mpY27RpU/HYbdu2FetRO27Xrl0t13fs2FE8dnR0tFiv006LrFq1qli/887y/56lNqJUnjJ8+fLl4rHRlNyovhS2D+fMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ0eevRFtRl7ayjnrhpWsEJGnz5s3FerS8dqlXHy0LHk0tjbaqjnrtpV79HXeUzz0rVqwo1qPXvfQzjZYcj547Wtp7KeDMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ0eevRHPHS33fqGe8cuXKYj3qxUf1gYGBhrVoXnk0rz2qR69b6bXp5FoBUnls0bgj/bD0dl2c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqbDZaWb7JX1R0ml3v7+6b6Okn0vaKWlC0uPuXp743efMrFgvzT2PesbR+vR154bPzs42rEV9/jNnzhTr0VbUpXUOJGloaKhhLXrNo9fl0qVLxXpp7HWOlfL0+X8s6ZFb7ntS0svufp+kl6vPASwhYfjd/RVJ5265+1FJB6rbByQ91uZxAeiwVn/nH3H3KUmqPg63b0gAuqHj1/ab2T5J+zr9PAA+nVbP/NNmNipJ1cfTjR7o7uPuPubuYy0+F4AOaDX8ByXtrW7vlfRie4YDoFvC8JvZ85L+V9KfmdmkmX1V0jOSHjazo5Ierj4HsISEv/O7+54Gpc+3eSw9VWf9+dJ8eileAz6at37t2rVi/erVqw1rMzMzxWPPnj1brEe9dncv1kvfeye/b6l8/UO0TkH0tefm5or1pYAr/ICkCD+QFOEHkiL8QFKEH0iK8ANJsXR3JdouuiRamjtql0WtwKidVmd6abQ1eVSPthffsmVLw9rq1auLx0bTkT/88MNivdTqu3LlSvHY6DWNfiZLAWd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKPn+lzjLS0ZTe6DqAaOnvqKdcqkdLa0fbfw8Pl5dnjPr8pW24b9y4UTy27vbhFy9ebFiru/R23e3D+wFnfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iij5/JerblnrxUZ++7hbcUU+6tBbB4OBg8dgdO3YU66Ojo8V6aQtuqbwketSnj5bujrbRLj13dF1HpM76D/1i6X8HAFpC+IGkCD+QFOEHkiL8QFKEH0iK8ANJhX1+M9sv6YuSTrv7/dV9T0v6mqQz1cOecvdfd2qQ3RD1+Ut93ahnHPWrozXko+3DS9cRrFq1qnhstHZ+tB5A9LqV1ta/dOlS8dioHr2upbFF12ZE9Szz+X8s6ZFF7v++uz9Q/bekgw9kFIbf3V+RdK4LYwHQRXV+53/CzH5rZvvNrHyNJ4C+02r4fyjpM5IekDQl6buNHmhm+8zskJkdavG5AHRAS+F392l3v+HuNyX9SNLuwmPH3X3M3cdaHSSA9msp/Ga2cKrXlyS93Z7hAOiWZlp9z0t6SNImM5uU9B1JD5nZA5Jc0oSkr3dwjAA6IAy/u+9Z5O5nOzCWvlZn/nbUj472mY/6/FFPuiRaO//q1au16qW182dmZorHRn3+6HUp/czqXNfRzHMvBVzhByRF+IGkCD+QFOEHkiL8QFKEH0iKpbsrdVo7dZeYjlp90RbdpS3Cz58/Xzx2xYoVxXr0vUXHl1qBs7OztZ67jmg59Kge/UyWAs78QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BUmj5/3SWo60wPrXsdQJ3lsaNlxaOlvaPrH9auXVusl0TfV9RLj763ubm5lmpSPNX5dsCZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSStPnj5aB3rp1a7FemrceLZ0dzXmPeu2Dg4Mt16OvXbe+cuXKYr3Uq4+2Jo967dE6CKXrK6JrK6L5/NF1AksBZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSCrs85vZdknPSdoi6aakcXf/gZltlPRzSTslTUh63N3Li8T3sainXOrlR33+qE+/YcOGYn3jxo3FemlOfTTfPvraq1evLtaj773Uy4+uvSht7y1JFy5caLkeXWNw+fLlYv3cuXPF+lLQzJn/uqRvuftnJf2VpG+Y2Z9LelLSy+5+n6SXq88BLBFh+N19yt3fqG7PSjosaaukRyUdqB52QNJjnRokgPb7VL/zm9lOSZ+T9KqkEXefkub/gZA03O7BAeicpq/tN7M1kn4p6ZvufjFaP23Bcfsk7WtteAA6pakzv5kNaD74P3H3X1V3T5vZaFUflXR6sWPdfdzdx9x9rB0DBtAeYfht/hT/rKTD7v69BaWDkvZWt/dKerH9wwPQKc287X9Q0j9IesvM3qzue0rSM5J+YWZflXRc0pc7M8T2iKam1tlGO5r+GS1RHS0rHrXjNm3a1LAWtfrWrVtXrEdLd0ftulK77f333y8eOzk5Was+PT3dsBZtXR5NF74dhOF39/+R1OgX/M+3dzgAuoUr/ICkCD+QFOEHkiL8QFKEH0iK8ANJpVm6O+rbRlM4S/3qs2fPFo8dHi5Pe4iml0aXUpfqUZ/+6tWrxXp0/cPU1FSxfuzYsYa1I0eOFI89evRosT4xMVGsz8zMNKydOHGieGwGnPmBpAg/kBThB5Ii/EBShB9IivADSRF+IKk0ff5ItBTzwMBAw1q0fHXUpy9tJd1MvTSff/369cVjI9G89+PHj7dcj/r0J0+eLNajn1m01kB2nPmBpAg/kBThB5Ii/EBShB9IivADSRF+IClz9+49mVn3nqyLhoaGivVobfzNmzcX6yMjI8V6ad3/5cuXF4+Nfv51t6ourYMwOztbPDbaoju6/iE6/nbl7k3tpceZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSCvv8ZrZd0nOStki6KWnc3X9gZk9L+pqkM9VDn3L3Xwdf67bs89cVXSewatWqYr20Nn+0bn/084/qc3Nzxfr09HTD2oYNG4rHlq4RQGPN9vmbWczjuqRvufsbZrZW0utm9lJV+767/2urgwTQO2H43X1K0lR1e9bMDkva2umBAeisT/U7v5ntlPQ5Sa9Wdz1hZr81s/1mtuh7VzPbZ2aHzOxQrZECaKumw29mayT9UtI33f2ipB9K+oykBzT/zuC7ix3n7uPuPubuY20YL4A2aSr8Zjag+eD/xN1/JUnuPu3uN9z9pqQfSdrduWECaLcw/Da/9Oyzkg67+/cW3D+64GFfkvR2+4cHoFOaafX9taT/lvSW5lt9kvSUpD2af8vvkiYkfb3642Dpa9Hq6zNRGzHa2hz9p9lWH/P5kyP8tx/m8wMoIvxAUoQfSIrwA0kRfiApwg8kRasPuM3Q6gNQRPiBpAg/kBThB5Ii/EBShB9IivADSTWzem87zUh6b8Hnm6r7+lG/jq1fxyUxtla1c2w7mn1gVy/y+cSTmx3q17X9+nVs/TouibG1qldj420/kBThB5LqdfjHe/z8Jf06tn4dl8TYWtWTsfX0d34AvdPrMz+AHulJ+M3sETM7YmbvmNmTvRhDI2Y2YWZvmdmbvd5irNoG7bSZvb3gvo1m9pKZHa0+lrf47e7Ynjazk9Vr96aZ/X2PxrbdzP7LzA6b2e/M7J+q+3v62hXG1ZPXretv+81smaQ/SnpY0qSk1yTtcfffd3UgDZjZhKQxd+95T9jM/kbSJUnPufv91X3/Iumcuz9T/cM55O7f7pOxPS3pUq93bq42lBlduLO0pMck/aN6+NoVxvW4evC69eLMv1vSO+5+zN2vSfqZpEd7MI6+5+6vSDp3y92PSjpQ3T6g+f95uq7B2PqCu0+5+xvV7VlJH+8s3dPXrjCunuhF+LdKOrHg80n115bfLuk3Zva6me3r9WAWMfLxzkjVx+Eej+dW4c7N3XTLztJ989q1suN1u/Ui/IstMdRPLYcH3f0vJf2dpG9Ub2/RnKZ2bu6WRXaW7gut7njdbr0I/6Sk7Qs+3ybpVA/GsSh3P1V9PC3pBfXf7sPTH2+SWn083ePx/L9+2rl5sZ2l1QevXT/teN2L8L8m6T4z22VmyyV9RdLBHozjE8xssPpDjMxsUNIX1H+7Dx+UtLe6vVfSiz0cy5/ol52bG+0srR6/dv2243VPLvKpWhn/JmmZpP3u/s9dH8QizOxezZ/tpfkZjz/t5djM7HlJD2l+1te0pO9I+ndJv5B0j6Tjkr7s7l3/w1uDsT2kT7lzc4fG1mhn6VfVw9eunTtet2U8XOEH5MQVfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvo/6QNYEqKyEI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(vae(inputs).data[0].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
